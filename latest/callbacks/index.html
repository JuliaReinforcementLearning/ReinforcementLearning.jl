<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Callbacks · ReinforcementLearning.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>ReinforcementLearning.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Introduction</a></li><li><a class="toctext" href="../usage/">Usage</a></li><li><a class="toctext" href="../tutorial/">Tutorial</a></li><li><span class="toctext">Reference</span><ul><li><a class="toctext" href="../comparison/">Comparison</a></li><li><a class="toctext" href="../learning/">Learning</a></li><li><a class="toctext" href="../learners/">Learners</a></li><li><a class="toctext" href="../buffers/">Buffers</a></li><li><a class="toctext" href="../environments/">Environments</a></li><li><a class="toctext" href="../stop/">Stopping Criteria</a></li><li><a class="toctext" href="../preprocessors/">Preprocessors</a></li><li><a class="toctext" href="../policies/">Policies</a></li><li class="current"><a class="toctext" href>Callbacks</a><ul class="internal"></ul></li><li><a class="toctext" href="../metrics/">Evaluation Metrics</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Reference</li><li><a href>Callbacks</a></li></ul><a class="edit-page" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/master/docs/src/callbacks.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Callbacks</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="callbacks-1" href="#callbacks-1">Callbacks</a></h1><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.AllRewards" href="#ReinforcementLearning.AllRewards"><code>ReinforcementLearning.AllRewards</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">struct AllRewards
    rewards::Array{Float64, 1}</code></pre><p>Records all rewards.</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/535ae54c5f17363f3324b87cd4b028bea047d867/src/callbacks.jl#L286-L291">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.AllRewards-Tuple{}" href="#ReinforcementLearning.AllRewards-Tuple{}"><code>ReinforcementLearning.AllRewards</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">AllRewards()</code></pre><p>Initializes with empty array.</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/535ae54c5f17363f3324b87cd4b028bea047d867/src/callbacks.jl#L295-L299">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.EvaluateGreedy-Tuple{Any,Any}" href="#ReinforcementLearning.EvaluateGreedy-Tuple{Any,Any}"><code>ReinforcementLearning.EvaluateGreedy</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">EvaluateGreedy(callback, stoppincriterion; every = Episode(10))</code></pre><p>Evaluate an rlsetup greedily by leaving the normal learning loop and evaluating the agent with <code>callback</code> until <code>stoppingcriterion</code> is met, at which point normal learning is resumed. This is done <code>every</code> Nth Episode (where N = 10 by default) or every Nth Step (e.g. <code>every = Step(10)</code>).</p><p>Example:</p><pre><code class="language-none">eg = EvaluateGreedy(EvaluationPerEpisode(TotalReward(), returnmean = true),
                    ConstantNumberEpisodes(10), every = Episode(100))
rlsetup = RLSetup(learner, environment, stoppingcriterion, callbacks = [eg])
learn!(rlsetup)
getvalue(eg)</code></pre><p>Leaves the learning loop every 100th episode to estimate the average total reward per episode, by running a greedy policy for 10 episodes.</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/535ae54c5f17363f3324b87cd4b028bea047d867/src/callbacks.jl#L178-L196">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.LinearDecreaseEpsilon" href="#ReinforcementLearning.LinearDecreaseEpsilon"><code>ReinforcementLearning.LinearDecreaseEpsilon</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">mutable struct LinearDecreaseEpsilon
    start::Int64
    stop::Int64
    initval::Float64
    finalval::Float64
    t::Int64
    step::Float64</code></pre><p>Linearly decrease ϵ of an <a href="@ref"><code>EpsilonGreedyPolicy</code></a> from <code>initval</code> until  step <code>start</code> to <code>finalval</code> at step <code>stop</code>.</p><p>Stepsize <code>step</code> = (finalval - initval)/(stop - start).</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/535ae54c5f17363f3324b87cd4b028bea047d867/src/callbacks.jl#L67-L80">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.LinearDecreaseEpsilon-NTuple{4,Any}" href="#ReinforcementLearning.LinearDecreaseEpsilon-NTuple{4,Any}"><code>ReinforcementLearning.LinearDecreaseEpsilon</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">LinearDecreaseEpsilon(start, stop, initval, finalval)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/535ae54c5f17363f3324b87cd4b028bea047d867/src/callbacks.jl#L90-L92">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.Progress" href="#ReinforcementLearning.Progress"><code>ReinforcementLearning.Progress</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">mutable struct Progress 
    steps::Int64
    laststopcountervalue::Int64</code></pre><p>Show <code>steps</code> times progress information during learning.</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/535ae54c5f17363f3324b87cd4b028bea047d867/src/callbacks.jl#L113-L119">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.Progress" href="#ReinforcementLearning.Progress"><code>ReinforcementLearning.Progress</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Progress(steps = 10) = Progress(steps, 0)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/535ae54c5f17363f3324b87cd4b028bea047d867/src/callbacks.jl#L124-L126">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.RecordAll" href="#ReinforcementLearning.RecordAll"><code>ReinforcementLearning.RecordAll</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">struct RecordAll
    rewards::Array{Float64, 1}
    actions::Array{Int64, 1}
    states::Array{Int64, 1}
    done::Array{Bool, 1}</code></pre><p>Records everything.</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/535ae54c5f17363f3324b87cd4b028bea047d867/src/callbacks.jl#L253-L261">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.RecordAll-Tuple{}" href="#ReinforcementLearning.RecordAll-Tuple{}"><code>ReinforcementLearning.RecordAll</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">RecordAll()</code></pre><p>Initializes with empty arrays.</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/535ae54c5f17363f3324b87cd4b028bea047d867/src/callbacks.jl#L268-L272">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.ReduceEpsilonPerEpisode" href="#ReinforcementLearning.ReduceEpsilonPerEpisode"><code>ReinforcementLearning.ReduceEpsilonPerEpisode</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">mutable struct ReduceEpsilonPerEpisode
    ϵ0::Float64
    counter::Int64</code></pre><p>Reduces ϵ of an <a href="@ref"><code>EpsilonGreedyPolicy</code></a> after each episode.</p><p>In episode n, ϵ = ϵ0/n</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/535ae54c5f17363f3324b87cd4b028bea047d867/src/callbacks.jl#L1-L9">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.ReduceEpsilonPerEpisode-Tuple{}" href="#ReinforcementLearning.ReduceEpsilonPerEpisode-Tuple{}"><code>ReinforcementLearning.ReduceEpsilonPerEpisode</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">ReduceEpsilonPerEpisode()</code></pre><p>Initialize callback.</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/535ae54c5f17363f3324b87cd4b028bea047d867/src/callbacks.jl#L14-L18">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.ReduceEpsilonPerT" href="#ReinforcementLearning.ReduceEpsilonPerT"><code>ReinforcementLearning.ReduceEpsilonPerT</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">mutable struct ReduceEpsilonPerT
    ϵ0::Float64
    T::Int64
    n::Int64
    counter::Int64</code></pre><p>Reduces ϵ of an <a href="@ref"><code>EpsilonGreedyPolicy</code></a> after every <code>T</code> steps.</p><p>After n * T steps, ϵ = ϵ0/n</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/535ae54c5f17363f3324b87cd4b028bea047d867/src/callbacks.jl#L31-L41">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.ReduceEpsilonPerT-Tuple{Any}" href="#ReinforcementLearning.ReduceEpsilonPerT-Tuple{Any}"><code>ReinforcementLearning.ReduceEpsilonPerT</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">ReduceEpsilonPerT()</code></pre><p>Initialize callback.</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/535ae54c5f17363f3324b87cd4b028bea047d867/src/callbacks.jl#L48-L52">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.Visualize" href="#ReinforcementLearning.Visualize"><code>ReinforcementLearning.Visualize</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">mutable struct Visualize 
    plot
    wait::Float64</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/535ae54c5f17363f3324b87cd4b028bea047d867/src/callbacks.jl#L311-L315">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.Visualize-Tuple{}" href="#ReinforcementLearning.Visualize-Tuple{}"><code>ReinforcementLearning.Visualize</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">Visualize(; wait = .15)</code></pre><p>A callback to be used in an <code>RLSetup</code> to visualize an environment during  running or learning.</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/blob/535ae54c5f17363f3324b87cd4b028bea047d867/src/callbacks.jl#L319-L324">source</a></section><footer><hr/><a class="previous" href="../policies/"><span class="direction">Previous</span><span class="title">Policies</span></a><a class="next" href="../metrics/"><span class="direction">Next</span><span class="title">Evaluation Metrics</span></a></footer></article></body></html>
